\hypertarget{regression_8h}{}\section{regression.\+h File Reference}
\label{regression_8h}\index{regression.\+h@{regression.\+h}}


Single, 1D Partitioned and 2D Partitioned Regression.  


{\ttfamily \#include $<$rjmcmc/rjmcmc\+\_\+config.\+h$>$}\\*
{\ttfamily \#include $<$rjmcmc/resultset1d.\+h$>$}\\*
{\ttfamily \#include $<$rjmcmc/dataset1d.\+h$>$}\\*
{\ttfamily \#include $<$rjmcmc/resultset2d.\+h$>$}\\*
{\ttfamily \#include $<$rjmcmc/dataset2d.\+h$>$}\\*
{\ttfamily \#include $<$rjmcmc/rjmcmc\+\_\+random.\+h$>$}\\*
Include dependency graph for regression.\+h\+:
% FIG 0
This graph shows which files directly or indirectly include this file\+:
% FIG 1
\subsection*{Typedefs}
\begin{DoxyCompactItemize}
\item 
typedef double($\ast$ \hyperlink{regression_8h_a7eaa245e668c18859c7c62c75a9732f6}{regression1d\+\_\+value\+\_\+at\+\_\+t}) (void $\ast$state, double \hyperlink{wellrng_8c_a676e0da0ef83bbbdf42538e54b97506b}{x})
\item 
typedef void($\ast$ \hyperlink{regression_8h_ae892a560d7749e7aa48352b053c54a26}{regression1d\+\_\+cb\+\_\+t}) (void $\ast$state, double $\ast$boundaries, int nboundaries, \hyperlink{regression_8h_a7eaa245e668c18859c7c62c75a9732f6}{regression1d\+\_\+value\+\_\+at\+\_\+t} value\+\_\+at, double lambda, void $\ast$\hyperlink{rjmcmcf__mpi_8h_ab68b3a27bfe943a73cf680c2e439e070}{user\+\_\+arg})
\item 
typedef double($\ast$ \hyperlink{regression_8h_a1669f9404bc2d78149c02d0cc39e0db8}{regression2d\+\_\+value\+\_\+at\+\_\+t}) (void $\ast$state, double \hyperlink{wellrng_8c_a676e0da0ef83bbbdf42538e54b97506b}{x}, double \hyperlink{wellrng_8c_ac30de26db5f6d1c18c63913729adca7d}{y})
\item 
typedef void($\ast$ \hyperlink{regression_8h_a7cb8595f1ee80ae521e3d10d6123dbf3}{regression2d\+\_\+cb\+\_\+t}) (void $\ast$state, double $\ast$\hyperlink{wellrng_8c_a676e0da0ef83bbbdf42538e54b97506b}{x}, double $\ast$\hyperlink{wellrng_8c_ac30de26db5f6d1c18c63913729adca7d}{y}, int ncells, \hyperlink{regression_8h_a1669f9404bc2d78149c02d0cc39e0db8}{regression2d\+\_\+value\+\_\+at\+\_\+t} value\+\_\+at, double lambda, void $\ast$\hyperlink{rjmcmcf__mpi_8h_ab68b3a27bfe943a73cf680c2e439e070}{user\+\_\+arg})
\end{DoxyCompactItemize}
\subsection*{Functions}
\begin{DoxyCompactItemize}
\item 
\hyperlink{resultset1d_8h_ae2ef1c63a8e796e51d39d8b7c2cdfa72}{resultset1d\+\_\+t} $\ast$ \hyperlink{regression_8h_a037d789bc3de5c4c55b0c781193ae3b7}{single1d\+\_\+regression} (const \hyperlink{dataset1d_8h_a232f8372957af83ed6a261e9b89dd8f6}{dataset1d\+\_\+t} $\ast$dataset, int burnin, int \hyperlink{rjmcmcf__mpi_8h_a1829e955eab35ef63200105c2de1ad94}{total}, int max\+\_\+order, int xsamples, int ysamples, double \hyperlink{rjmcmcf__mpi_8h_a5a7722a5cc210713ec1b3956fde06e70}{credible\+\_\+interval}, \hyperlink{rjmcmc__random_8h_accc36e83459ada552d8f70962190dac0}{rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t} \hyperlink{rjmcmcf__mpi_8h_a361f30102277b1d490d4edc190afccf6}{random}, \hyperlink{rjmcmc__random_8h_a498625755d377b68ad37c9ab360e83b0}{rjmcmc\+\_\+normal\+\_\+rand\+\_\+t} \hyperlink{rjmcmcf__mpi_8h_a6304ff7c79f9217c47a3373e460e3cfc}{normal}, int results, \hyperlink{regression_8h_ae892a560d7749e7aa48352b053c54a26}{regression1d\+\_\+cb\+\_\+t} user\+\_\+callback, void $\ast$\hyperlink{rjmcmcf__mpi_8h_ab68b3a27bfe943a73cf680c2e439e070}{user\+\_\+arg})
\begin{DoxyCompactList}\small\item\em Single Partition Regression. \end{DoxyCompactList}\item 
\hyperlink{resultset1d_8h_ae2ef1c63a8e796e51d39d8b7c2cdfa72}{resultset1d\+\_\+t} $\ast$ \hyperlink{regression_8h_ac8c2d9357e8a0ac1ff03fc48843e804b}{single1d\+\_\+regression\+\_\+with\+\_\+prior} (const \hyperlink{dataset1d_8h_a232f8372957af83ed6a261e9b89dd8f6}{dataset1d\+\_\+t} $\ast$dataset, const double $\ast$prior, int burnin, int \hyperlink{rjmcmcf__mpi_8h_a1829e955eab35ef63200105c2de1ad94}{total}, int max\+\_\+order, int xsamples, int ysamples, double \hyperlink{rjmcmcf__mpi_8h_a5a7722a5cc210713ec1b3956fde06e70}{credible\+\_\+interval}, \hyperlink{rjmcmc__random_8h_accc36e83459ada552d8f70962190dac0}{rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t} \hyperlink{rjmcmcf__mpi_8h_a361f30102277b1d490d4edc190afccf6}{random}, \hyperlink{rjmcmc__random_8h_a498625755d377b68ad37c9ab360e83b0}{rjmcmc\+\_\+normal\+\_\+rand\+\_\+t} \hyperlink{rjmcmcf__mpi_8h_a6304ff7c79f9217c47a3373e460e3cfc}{normal}, int results, \hyperlink{regression_8h_ae892a560d7749e7aa48352b053c54a26}{regression1d\+\_\+cb\+\_\+t} user\+\_\+callback, void $\ast$\hyperlink{rjmcmcf__mpi_8h_ab68b3a27bfe943a73cf680c2e439e070}{user\+\_\+arg})
\begin{DoxyCompactList}\small\item\em Single Partition Regression with a custom prior. \end{DoxyCompactList}\item 
\hyperlink{resultset1d_8h_ae2ef1c63a8e796e51d39d8b7c2cdfa72}{resultset1d\+\_\+t} $\ast$ \hyperlink{regression_8h_a0ab9525ab0dc478cfa18bc9bd5a94d97}{single1d\+\_\+direct\+\_\+regression} (const \hyperlink{dataset1d_8h_a232f8372957af83ed6a261e9b89dd8f6}{dataset1d\+\_\+t} $\ast$dataset, const double $\ast$fixed\+\_\+prior, int max\+\_\+order, int xsamples, \hyperlink{rjmcmc__random_8h_accc36e83459ada552d8f70962190dac0}{rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t} \hyperlink{rjmcmcf__mpi_8h_a361f30102277b1d490d4edc190afccf6}{random}, \hyperlink{rjmcmc__random_8h_a498625755d377b68ad37c9ab360e83b0}{rjmcmc\+\_\+normal\+\_\+rand\+\_\+t} \hyperlink{rjmcmcf__mpi_8h_a6304ff7c79f9217c47a3373e460e3cfc}{normal})
\begin{DoxyCompactList}\small\item\em Single Partition Regression with direct integration. \end{DoxyCompactList}\item 
\hyperlink{resultset1d_8h_ae2ef1c63a8e796e51d39d8b7c2cdfa72}{resultset1d\+\_\+t} $\ast$ \hyperlink{regression_8h_a17bc74fa9fb9c6287ab4e19751c6bb17}{part1d\+\_\+regression} (const \hyperlink{dataset1d_8h_a232f8372957af83ed6a261e9b89dd8f6}{dataset1d\+\_\+t} $\ast$dataset, int burnin, int \hyperlink{rjmcmcf__mpi_8h_a1829e955eab35ef63200105c2de1ad94}{total}, int min\+\_\+part, int max\+\_\+part, int max\+\_\+order, int xsamples, int ysamples, double \hyperlink{rjmcmcf__mpi_8h_a5a7722a5cc210713ec1b3956fde06e70}{credible\+\_\+interval}, double pd, \hyperlink{rjmcmc__random_8h_accc36e83459ada552d8f70962190dac0}{rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t} \hyperlink{rjmcmcf__mpi_8h_a361f30102277b1d490d4edc190afccf6}{random}, \hyperlink{rjmcmc__random_8h_a498625755d377b68ad37c9ab360e83b0}{rjmcmc\+\_\+normal\+\_\+rand\+\_\+t} \hyperlink{rjmcmcf__mpi_8h_a6304ff7c79f9217c47a3373e460e3cfc}{normal}, int results, \hyperlink{regression_8h_ae892a560d7749e7aa48352b053c54a26}{regression1d\+\_\+cb\+\_\+t} callback, void $\ast$\hyperlink{rjmcmcf__mpi_8h_ab68b3a27bfe943a73cf680c2e439e070}{user\+\_\+arg})
\begin{DoxyCompactList}\small\item\em Multiple partition arbitrary order regression. \end{DoxyCompactList}\item 
\hyperlink{resultset1d_8h_ae2ef1c63a8e796e51d39d8b7c2cdfa72}{resultset1d\+\_\+t} $\ast$ \hyperlink{regression_8h_ab17dfbf7aa5a8f0ba54441e7e9dc33cf}{part1d\+\_\+zero\+\_\+regression} (const \hyperlink{dataset1d_8h_a232f8372957af83ed6a261e9b89dd8f6}{dataset1d\+\_\+t} $\ast$dataset, int burnin, int \hyperlink{rjmcmcf__mpi_8h_a1829e955eab35ef63200105c2de1ad94}{total}, int min\+\_\+part, int max\+\_\+part, int xsamples, int ysamples, double \hyperlink{rjmcmcf__mpi_8h_a5a7722a5cc210713ec1b3956fde06e70}{credible\+\_\+interval}, double pd, \hyperlink{rjmcmc__random_8h_accc36e83459ada552d8f70962190dac0}{rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t} \hyperlink{rjmcmcf__mpi_8h_a361f30102277b1d490d4edc190afccf6}{random}, \hyperlink{rjmcmc__random_8h_a498625755d377b68ad37c9ab360e83b0}{rjmcmc\+\_\+normal\+\_\+rand\+\_\+t} \hyperlink{rjmcmcf__mpi_8h_a6304ff7c79f9217c47a3373e460e3cfc}{normal}, int results, \hyperlink{regression_8h_ae892a560d7749e7aa48352b053c54a26}{regression1d\+\_\+cb\+\_\+t} callback, void $\ast$\hyperlink{rjmcmcf__mpi_8h_ab68b3a27bfe943a73cf680c2e439e070}{user\+\_\+arg})
\begin{DoxyCompactList}\small\item\em Multiple partition zeroth order regression. \end{DoxyCompactList}\item 
\hyperlink{resultset1d_8h_ae2ef1c63a8e796e51d39d8b7c2cdfa72}{resultset1d\+\_\+t} $\ast$ \hyperlink{regression_8h_abd2a0dc74a4bb3934c21c7864759bbbd}{part1d\+\_\+natural\+\_\+regression} (const \hyperlink{dataset1d_8h_a232f8372957af83ed6a261e9b89dd8f6}{dataset1d\+\_\+t} $\ast$dataset, int burnin, int \hyperlink{rjmcmcf__mpi_8h_a1829e955eab35ef63200105c2de1ad94}{total}, int min\+\_\+part, int max\+\_\+part, int xsamples, int ysamples, double \hyperlink{rjmcmcf__mpi_8h_a5a7722a5cc210713ec1b3956fde06e70}{credible\+\_\+interval}, double pv, double pd, \hyperlink{rjmcmc__random_8h_accc36e83459ada552d8f70962190dac0}{rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t} \hyperlink{rjmcmcf__mpi_8h_a361f30102277b1d490d4edc190afccf6}{random}, \hyperlink{rjmcmc__random_8h_a498625755d377b68ad37c9ab360e83b0}{rjmcmc\+\_\+normal\+\_\+rand\+\_\+t} \hyperlink{rjmcmcf__mpi_8h_a6304ff7c79f9217c47a3373e460e3cfc}{normal}, int results, \hyperlink{regression_8h_ae892a560d7749e7aa48352b053c54a26}{regression1d\+\_\+cb\+\_\+t} callback, void $\ast$\hyperlink{rjmcmcf__mpi_8h_ab68b3a27bfe943a73cf680c2e439e070}{user\+\_\+arg})
\begin{DoxyCompactList}\small\item\em Multiple partition joined line segments regression. \end{DoxyCompactList}\item 
\hyperlink{resultset2d_8h_a7d7cd3bde6bca10a8480a58c69d3787e}{resultset2d\+\_\+t} $\ast$ \hyperlink{regression_8h_aa4589a0fbb1ca56b2db6fafbda40161f}{part2d\+\_\+regression} (const \hyperlink{dataset2d_8h_a942e85acecf08479c1a4e58600cfe40a}{dataset2d\+\_\+t} $\ast$dataset, int burnin, int \hyperlink{rjmcmcf__mpi_8h_a1829e955eab35ef63200105c2de1ad94}{total}, int min\+\_\+part, int max\+\_\+part, int xsamples, int ysamples, int zsamples, double \hyperlink{rjmcmcf__mpi_8h_a5a7722a5cc210713ec1b3956fde06e70}{credible\+\_\+interval}, double pv, double pd, \hyperlink{rjmcmc__random_8h_accc36e83459ada552d8f70962190dac0}{rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t} \hyperlink{rjmcmcf__mpi_8h_a361f30102277b1d490d4edc190afccf6}{random}, \hyperlink{rjmcmc__random_8h_a498625755d377b68ad37c9ab360e83b0}{rjmcmc\+\_\+normal\+\_\+rand\+\_\+t} \hyperlink{rjmcmcf__mpi_8h_a6304ff7c79f9217c47a3373e460e3cfc}{normal}, int results, \hyperlink{regression_8h_a7cb8595f1ee80ae521e3d10d6123dbf3}{regression2d\+\_\+cb\+\_\+t} user\+\_\+callback, void $\ast$\hyperlink{rjmcmcf__mpi_8h_ab68b3a27bfe943a73cf680c2e439e070}{user\+\_\+arg})
\end{DoxyCompactItemize}


\subsection{Detailed Description}
Single, 1D Partitioned and 2D Partitioned Regression. 

The regression functions run a M\+C\+MC simulation to fit data using regression metrics. The likelihood is calculated as a gaussian probability distribution, ie\+:

\[ \Pr(d|m) = \frac{1}{\prod_{i=1}^n \sqrt{2 \pi \cdot \sigma_i^2}} \exp{\left( \sum_{i = 1}^n \frac{-\left(g\left(m\right)_i - d_i\right)^2}{2\sigma_i^2}\right)} \]

Where $d$ is the data, $m$ is the proposed model and $\sigma$ is the per data point error (uncorrelated). Hierarchical regression is also supported for all of the regression methods by configuring the lambda parameters in the 1D and 2D dataset structures (by setting the lambda perturbation deviation to a non-\/zero value). This changes the likelihood slightly to include the $\lambda$ term as follows\+:

\[ \Pr(d|m) = \frac{1}{\prod_{i=1}^n \sqrt{2 \pi \cdot (\lambda \cdot \sigma_i)^2}} \exp{\left( \sum_{i = 1}^n \frac{-\left(g\left(m\right)_i - d_i\right)^2}{2(\lambda \cdot \sigma_i)^2}\right)} \]

In each of the methods, the results returned are configurable by setting the results parameter using flags. See the \hyperlink{resultset1d_8h_ae2ef1c63a8e796e51d39d8b7c2cdfa72}{resultset1d\+\_\+t} and \hyperlink{resultset2d_8h_a7d7cd3bde6bca10a8480a58c69d3787e}{resultset2d\+\_\+t} types. The default result is just the mean of the ensembles. 

\subsection{Typedef Documentation}
\index{regression.\+h@{regression.\+h}!regression1d\+\_\+cb\+\_\+t@{regression1d\+\_\+cb\+\_\+t}}
\index{regression1d\+\_\+cb\+\_\+t@{regression1d\+\_\+cb\+\_\+t}!regression.\+h@{regression.\+h}}
\subsubsection[{\texorpdfstring{regression1d\+\_\+cb\+\_\+t}{regression1d_cb_t}}]{\setlength{\rightskip}{0pt plus 5cm}typedef void($\ast$ regression1d\+\_\+cb\+\_\+t) (void $\ast$state, double $\ast$boundaries, int nboundaries, {\bf regression1d\+\_\+value\+\_\+at\+\_\+t} value\+\_\+at, double lambda, void $\ast${\bf user\+\_\+arg})}\hypertarget{regression_8h_ae892a560d7749e7aa48352b053c54a26}{}\label{regression_8h_ae892a560d7749e7aa48352b053c54a26}
\index{regression.\+h@{regression.\+h}!regression1d\+\_\+value\+\_\+at\+\_\+t@{regression1d\+\_\+value\+\_\+at\+\_\+t}}
\index{regression1d\+\_\+value\+\_\+at\+\_\+t@{regression1d\+\_\+value\+\_\+at\+\_\+t}!regression.\+h@{regression.\+h}}
\subsubsection[{\texorpdfstring{regression1d\+\_\+value\+\_\+at\+\_\+t}{regression1d_value_at_t}}]{\setlength{\rightskip}{0pt plus 5cm}typedef double($\ast$ regression1d\+\_\+value\+\_\+at\+\_\+t) (void $\ast$state, double {\bf x})}\hypertarget{regression_8h_a7eaa245e668c18859c7c62c75a9732f6}{}\label{regression_8h_a7eaa245e668c18859c7c62c75a9732f6}
\begin{Desc}
\item[Examples\+: ]\par
\hyperlink{1d_2partitioned_2regression_2zeromultistep_2zeromultistep_8c-example}{1d/partitioned/regression/zeromultistep/zeromultistep.\+c}.\end{Desc}
\index{regression.\+h@{regression.\+h}!regression2d\+\_\+cb\+\_\+t@{regression2d\+\_\+cb\+\_\+t}}
\index{regression2d\+\_\+cb\+\_\+t@{regression2d\+\_\+cb\+\_\+t}!regression.\+h@{regression.\+h}}
\subsubsection[{\texorpdfstring{regression2d\+\_\+cb\+\_\+t}{regression2d_cb_t}}]{\setlength{\rightskip}{0pt plus 5cm}typedef void($\ast$ regression2d\+\_\+cb\+\_\+t) (void $\ast$state, double $\ast${\bf x}, double $\ast${\bf y}, int ncells, {\bf regression2d\+\_\+value\+\_\+at\+\_\+t} value\+\_\+at, double lambda, void $\ast${\bf user\+\_\+arg})}\hypertarget{regression_8h_a7cb8595f1ee80ae521e3d10d6123dbf3}{}\label{regression_8h_a7cb8595f1ee80ae521e3d10d6123dbf3}
\index{regression.\+h@{regression.\+h}!regression2d\+\_\+value\+\_\+at\+\_\+t@{regression2d\+\_\+value\+\_\+at\+\_\+t}}
\index{regression2d\+\_\+value\+\_\+at\+\_\+t@{regression2d\+\_\+value\+\_\+at\+\_\+t}!regression.\+h@{regression.\+h}}
\subsubsection[{\texorpdfstring{regression2d\+\_\+value\+\_\+at\+\_\+t}{regression2d_value_at_t}}]{\setlength{\rightskip}{0pt plus 5cm}typedef double($\ast$ regression2d\+\_\+value\+\_\+at\+\_\+t) (void $\ast$state, double {\bf x}, double {\bf y})}\hypertarget{regression_8h_a1669f9404bc2d78149c02d0cc39e0db8}{}\label{regression_8h_a1669f9404bc2d78149c02d0cc39e0db8}
\begin{Desc}
\item[Examples\+: ]\par
\hyperlink{2d_2partitioned_2regression_2callbackex_2callbackex_8c-example}{2d/partitioned/regression/callbackex/callbackex.\+c}.\end{Desc}


\subsection{Function Documentation}
\index{regression.\+h@{regression.\+h}!part1d\+\_\+natural\+\_\+regression@{part1d\+\_\+natural\+\_\+regression}}
\index{part1d\+\_\+natural\+\_\+regression@{part1d\+\_\+natural\+\_\+regression}!regression.\+h@{regression.\+h}}
\subsubsection[{\texorpdfstring{part1d\+\_\+natural\+\_\+regression(const dataset1d\+\_\+t $\ast$dataset, int burnin, int total, int min\+\_\+part, int max\+\_\+part, int xsamples, int ysamples, double credible\+\_\+interval, double pv, double pd, rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t random, rjmcmc\+\_\+normal\+\_\+rand\+\_\+t normal, int results, regression1d\+\_\+cb\+\_\+t callback, void $\ast$user\+\_\+arg)}{part1d_natural_regression(const dataset1d_t *dataset, int burnin, int total, int min_part, int max_part, int xsamples, int ysamples, double credible_interval, double pv, double pd, rjmcmc_uniform_rand_t random, rjmcmc_normal_rand_t normal, int results, regression1d_cb_t callback, void *user_arg)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf resultset1d\+\_\+t}$\ast$ part1d\+\_\+natural\+\_\+regression (
\begin{DoxyParamCaption}
\item[{const {\bf dataset1d\+\_\+t} $\ast$}]{dataset, }
\item[{int}]{burnin, }
\item[{int}]{total, }
\item[{int}]{min\+\_\+part, }
\item[{int}]{max\+\_\+part, }
\item[{int}]{xsamples, }
\item[{int}]{ysamples, }
\item[{double}]{credible\+\_\+interval, }
\item[{double}]{pv, }
\item[{double}]{pd, }
\item[{{\bf rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t}}]{random, }
\item[{{\bf rjmcmc\+\_\+normal\+\_\+rand\+\_\+t}}]{normal, }
\item[{int}]{results, }
\item[{{\bf regression1d\+\_\+cb\+\_\+t}}]{callback, }
\item[{void $\ast$}]{user\+\_\+arg}
\end{DoxyParamCaption}
)}\hypertarget{regression_8h_abd2a0dc74a4bb3934c21c7864759bbbd}{}\label{regression_8h_abd2a0dc74a4bb3934c21c7864759bbbd}


Multiple partition joined line segments regression. 

This method uses joined line segments between partitions so that a continuous function is formed to fit the data. This is useful for determining changes in gradient in the data.


\begin{DoxyParams}{Parameters}
{\em dataset} & The dataset to run the regression on. See the \hyperlink{dataset1d_8h_a12b327d93f135ffa89af1d4d2359f771}{dataset1d\+\_\+load\+\_\+known}, \+::dataset1d\+\_\+load\+\_\+estimated, and \hyperlink{dataset1d_8h_a8a3dee8031d5f30f9698874806bb33be}{dataset1d\+\_\+load\+\_\+fixed} functions. \\
\hline
{\em burnin} & The number of burn in iterations. \\
\hline
{\em total} & The total number of iterations. \\
\hline
{\em min\+\_\+part} & The minimum number of partitions to allow. \\
\hline
{\em max\+\_\+part} & The maximum number of partitions to allow. to the data. \\
\hline
{\em xsamples} & The number of samples to use for discretization of the horizontal axis. \\
\hline
{\em ysamples} & The number of samples to use for discretization of the vertical axis when computing mode, median, and credible intervals. \\
\hline
{\em credible\+\_\+interval} & The credible interval to use for results expressed as a ratio, i.\+e. 0.\+95 for the 95\% credible interval. \\
\hline
{\em pv} & The standard deviation to use when peturbing the y value of a partition. This is needed since we can no longer use the data to determine this. A rule of thumb for selecting this value is to make it around 5 to 10 percent of the range of the data. \\
\hline
{\em pd} & The standard deviation to use when peturbing the x-\/position of a partition. The new position is moved by N(0, pd). \\
\hline
{\em random} & A function pointer to uniform random number generator to use. See the \hyperlink{rjmcmc__random_8h_ab82b2ece8acc3f5a05ff2f270794f9be}{rjmcmc\+\_\+uniform} function. \\
\hline
{\em normal} & A function pointer to the normal random number generator for generating normally distributed random numbers with 0 mean and a standard deviation of 1. See the \hyperlink{rjmcmc__random_8h_a0f9b049cec5095e2e1c1b3488de1d5c0}{rjmcmc\+\_\+normal} function. \\
\hline
{\em results} & A bit mask of results to store. See \hyperlink{resultset1d_8h_a1fffe49407333be24faf49976523f7a0}{resultset1d\+\_\+result\+\_\+t}. \\
\hline
{\em callback} & A user function to call for every sample for collecting extra statistics. Set to N\+U\+LL if this is not needed. \\
\hline
{\em user\+\_\+arg} & The user argument to pass to the callback function. \\
\hline
\end{DoxyParams}


References part1d\+::accepted, part1d\+::birth\+\_\+prob, part1d\+::current, part1d\+::current\+\_\+like, part1d\+::dataset, part1d\+::death\+\_\+prob, part1d\+::dy, part1d\+::lambda\+\_\+prob, \+\_\+dataset1d\+::lambdastd, part1d\+::move\+\_\+prob, part1d\+::normal, part1d\+::nprocesses, part1d\+::out, part1d\+\_\+natural\+\_\+rj\+\_\+clone(), part1d\+\_\+natural\+\_\+rj\+\_\+create(), part1d\+\_\+natural\+\_\+rj\+\_\+evaluate(), part1d\+\_\+natural\+\_\+rj\+\_\+evaluate\+\_\+gradient(), part1d\+\_\+natural\+\_\+rj\+\_\+initialize(), part1d\+\_\+natural\+\_\+rj\+\_\+lambda(), part1d\+\_\+natural\+\_\+rj\+\_\+misfit(), part1d\+\_\+natural\+\_\+rj\+\_\+partition\+\_\+position(), part1d\+\_\+natural\+\_\+rj\+\_\+partitions(), part1d\+\_\+natural\+\_\+rj\+\_\+propose\+\_\+birth(), part1d\+\_\+natural\+\_\+rj\+\_\+propose\+\_\+death(), part1d\+\_\+natural\+\_\+rj\+\_\+propose\+\_\+lambda(), part1d\+\_\+natural\+\_\+rj\+\_\+propose\+\_\+move(), part1d\+\_\+natural\+\_\+rj\+\_\+propose\+\_\+value(), part1d\+::partitions, part1d\+::process, part1d\+::proposed, part1d\+::proposed\+\_\+like, part1d\+::random, part1d\+::results, resultset1d\+\_\+accept(), resultset1d\+\_\+assemble\+\_\+results(), resultset1d\+\_\+create(), resultset1d\+\_\+propose(), resultset1d\+\_\+sample(), resultset1d\+\_\+sample\+\_\+gradient(), resultset1d\+\_\+sample\+\_\+lambda(), resultset1d\+\_\+sample\+\_\+misfit(), resultset1d\+\_\+sample\+\_\+npartitions(), resultset1d\+\_\+sample\+\_\+partition\+\_\+x(), rjmcmc\+\_\+create\+\_\+array\+\_\+1d(), rjmcmc\+\_\+destroy\+\_\+array\+\_\+1d(), rjmcmc\+\_\+engine\+\_\+run(), rjmcmc\+\_\+error(), part1d\+::user\+\_\+arg, part1d\+::user\+\_\+callback, part1d\+::v, part1d\+::value\+\_\+prob, \+\_\+dataset1d\+::xmax, \+\_\+dataset1d\+::xmin, part1d\+::xsamples, \+\_\+dataset1d\+::ymax, and \+\_\+dataset1d\+::ymin.

\index{regression.\+h@{regression.\+h}!part1d\+\_\+regression@{part1d\+\_\+regression}}
\index{part1d\+\_\+regression@{part1d\+\_\+regression}!regression.\+h@{regression.\+h}}
\subsubsection[{\texorpdfstring{part1d\+\_\+regression(const dataset1d\+\_\+t $\ast$dataset, int burnin, int total, int min\+\_\+part, int max\+\_\+part, int max\+\_\+order, int xsamples, int ysamples, double credible\+\_\+interval, double pd, rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t random, rjmcmc\+\_\+normal\+\_\+rand\+\_\+t normal, int results, regression1d\+\_\+cb\+\_\+t callback, void $\ast$user\+\_\+arg)}{part1d_regression(const dataset1d_t *dataset, int burnin, int total, int min_part, int max_part, int max_order, int xsamples, int ysamples, double credible_interval, double pd, rjmcmc_uniform_rand_t random, rjmcmc_normal_rand_t normal, int results, regression1d_cb_t callback, void *user_arg)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf resultset1d\+\_\+t}$\ast$ part1d\+\_\+regression (
\begin{DoxyParamCaption}
\item[{const {\bf dataset1d\+\_\+t} $\ast$}]{dataset, }
\item[{int}]{burnin, }
\item[{int}]{total, }
\item[{int}]{min\+\_\+part, }
\item[{int}]{max\+\_\+part, }
\item[{int}]{max\+\_\+order, }
\item[{int}]{xsamples, }
\item[{int}]{ysamples, }
\item[{double}]{credible\+\_\+interval, }
\item[{double}]{pd, }
\item[{{\bf rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t}}]{random, }
\item[{{\bf rjmcmc\+\_\+normal\+\_\+rand\+\_\+t}}]{normal, }
\item[{int}]{results, }
\item[{{\bf regression1d\+\_\+cb\+\_\+t}}]{callback, }
\item[{void $\ast$}]{user\+\_\+arg}
\end{DoxyParamCaption}
)}\hypertarget{regression_8h_a17bc74fa9fb9c6287ab4e19751c6bb17}{}\label{regression_8h_a17bc74fa9fb9c6287ab4e19751c6bb17}


Multiple partition arbitrary order regression. 

This method fits up to max\+\_\+order polynomials into a partitioned dataset. The number of partitions and order of polynomials within each partition is determined by the data. If higher order polynomials are permitted (ie $>$ 5) then there can be \char`\"{}ringing\char`\"{} near any discontinuities in the data as a higher order polynomial may fit a discontinuity as well as a 2 discontinuous polynomials. For this reason care should be taken with setting the max\+\_\+order parameter.


\begin{DoxyParams}{Parameters}
{\em dataset} & The dataset to run the regression on. See the \hyperlink{dataset1d_8h_a12b327d93f135ffa89af1d4d2359f771}{dataset1d\+\_\+load\+\_\+known}, \+::dataset1d\+\_\+load\+\_\+estimated, and \hyperlink{dataset1d_8h_a8a3dee8031d5f30f9698874806bb33be}{dataset1d\+\_\+load\+\_\+fixed} functions. \\
\hline
{\em burnin} & The number of burn in iterations. \\
\hline
{\em total} & The total number of iterations. \\
\hline
{\em min\+\_\+part} & The minimum number of partitions to allow. \\
\hline
{\em max\+\_\+part} & The maximum number of partitions to allow. \\
\hline
{\em max\+\_\+order} & The maximum order of the fitting polynomial. to the data. \\
\hline
{\em xsamples} & The number of samples to use for discretization of the horizontal axis. \\
\hline
{\em ysamples} & The number of samples to use for discretization of the vertical axis when computing mode, median, and credible intervals. \\
\hline
{\em credible\+\_\+interval} & The credible interval to use for results expressed as a ratio, i.\+e. 0.\+95 for the 95\% credible interval. \\
\hline
{\em pd} & The standard deviation to use when peturbing the x-\/position of a partition. The new position is moved by N(0, pd). \\
\hline
{\em random} & A function pointer to uniform random number generator to use. See the \hyperlink{rjmcmc__random_8h_ab82b2ece8acc3f5a05ff2f270794f9be}{rjmcmc\+\_\+uniform} function. \\
\hline
{\em normal} & A function pointer to the normal random number generator for generating normally distributed random numbers with 0 mean and a standard deviation of 1. See the \hyperlink{rjmcmc__random_8h_a0f9b049cec5095e2e1c1b3488de1d5c0}{rjmcmc\+\_\+normal} function. \\
\hline
{\em results} & A bit mask of results to store. See \hyperlink{resultset1d_8h_a1fffe49407333be24faf49976523f7a0}{resultset1d\+\_\+result\+\_\+t}. \\
\hline
{\em callback} & A user function to call for every sample for collecting extra statistics. Set to N\+U\+LL if this is not needed. \\
\hline
{\em user\+\_\+arg} & The user argument to pass to the callback function. \\
\hline
\end{DoxyParams}


References part1d\+::accepted, part1d\+::birth\+\_\+prob, part1d\+::current, part1d\+::current\+\_\+like, part1d\+::dataset, part1d\+::death\+\_\+prob, part1d\+::dk, part1d\+::dy, part1d\+::lambda\+\_\+prob, \+\_\+dataset1d\+::lambdastd, part1d\+::move\+\_\+prob, part1d\+::normal, part1d\+::nprocesses, part1d\+::out, part1d\+\_\+regression\+\_\+rj\+\_\+clone(), part1d\+\_\+regression\+\_\+rj\+\_\+create(), part1d\+\_\+regression\+\_\+rj\+\_\+destroy(), part1d\+\_\+regression\+\_\+rj\+\_\+evaluate(), part1d\+\_\+regression\+\_\+rj\+\_\+initialize(), part1d\+\_\+regression\+\_\+rj\+\_\+lambda(), part1d\+\_\+regression\+\_\+rj\+\_\+misfit(), part1d\+\_\+regression\+\_\+rj\+\_\+order(), part1d\+\_\+regression\+\_\+rj\+\_\+partition\+\_\+position(), part1d\+\_\+regression\+\_\+rj\+\_\+partitions(), part1d\+\_\+regression\+\_\+rj\+\_\+propose\+\_\+birth(), part1d\+\_\+regression\+\_\+rj\+\_\+propose\+\_\+death(), part1d\+\_\+regression\+\_\+rj\+\_\+propose\+\_\+lambda(), part1d\+\_\+regression\+\_\+rj\+\_\+propose\+\_\+move(), part1d\+\_\+regression\+\_\+rj\+\_\+propose\+\_\+value(), part1d\+::partitions, part1d\+::process, part1d\+::proposed, part1d\+::proposed\+\_\+like, part1d\+::random, part1d\+::results, resultset1d\+\_\+accept(), resultset1d\+\_\+assemble\+\_\+results(), resultset1d\+\_\+create(), resultset1d\+\_\+propose(), resultset1d\+\_\+sample(), resultset1d\+\_\+sample\+\_\+lambda(), resultset1d\+\_\+sample\+\_\+misfit(), resultset1d\+\_\+sample\+\_\+npartitions(), resultset1d\+\_\+sample\+\_\+order(), resultset1d\+\_\+sample\+\_\+partition\+\_\+x(), rjmcmc\+\_\+create\+\_\+array\+\_\+1d(), rjmcmc\+\_\+destroy\+\_\+array\+\_\+1d(), rjmcmc\+\_\+engine\+\_\+run(), rjmcmc\+\_\+error(), rjmcmc\+\_\+random\+\_\+choose\+\_\+int(), part1d\+::user\+\_\+arg, part1d\+::user\+\_\+callback, part1d\+::v, part1d\+::value\+\_\+prob, \+\_\+dataset1d\+::xmax, \+\_\+dataset1d\+::xmin, part1d\+::xsamples, \+\_\+dataset1d\+::ymax, and \+\_\+dataset1d\+::ymin.

\index{regression.\+h@{regression.\+h}!part1d\+\_\+zero\+\_\+regression@{part1d\+\_\+zero\+\_\+regression}}
\index{part1d\+\_\+zero\+\_\+regression@{part1d\+\_\+zero\+\_\+regression}!regression.\+h@{regression.\+h}}
\subsubsection[{\texorpdfstring{part1d\+\_\+zero\+\_\+regression(const dataset1d\+\_\+t $\ast$dataset, int burnin, int total, int min\+\_\+part, int max\+\_\+part, int xsamples, int ysamples, double credible\+\_\+interval, double pd, rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t random, rjmcmc\+\_\+normal\+\_\+rand\+\_\+t normal, int results, regression1d\+\_\+cb\+\_\+t callback, void $\ast$user\+\_\+arg)}{part1d_zero_regression(const dataset1d_t *dataset, int burnin, int total, int min_part, int max_part, int xsamples, int ysamples, double credible_interval, double pd, rjmcmc_uniform_rand_t random, rjmcmc_normal_rand_t normal, int results, regression1d_cb_t callback, void *user_arg)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf resultset1d\+\_\+t}$\ast$ part1d\+\_\+zero\+\_\+regression (
\begin{DoxyParamCaption}
\item[{const {\bf dataset1d\+\_\+t} $\ast$}]{dataset, }
\item[{int}]{burnin, }
\item[{int}]{total, }
\item[{int}]{min\+\_\+part, }
\item[{int}]{max\+\_\+part, }
\item[{int}]{xsamples, }
\item[{int}]{ysamples, }
\item[{double}]{credible\+\_\+interval, }
\item[{double}]{pd, }
\item[{{\bf rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t}}]{random, }
\item[{{\bf rjmcmc\+\_\+normal\+\_\+rand\+\_\+t}}]{normal, }
\item[{int}]{results, }
\item[{{\bf regression1d\+\_\+cb\+\_\+t}}]{callback, }
\item[{void $\ast$}]{user\+\_\+arg}
\end{DoxyParamCaption}
)}\hypertarget{regression_8h_ab17dfbf7aa5a8f0ba54441e7e9dc33cf}{}\label{regression_8h_ab17dfbf7aa5a8f0ba54441e7e9dc33cf}


Multiple partition zeroth order regression. 

This method computes a regression using multiple partitions with zeroth order curves in each partition. The level of the curve is determined from the data within each partition (i.\+e. sampled from the mean and standard deviation). The exception is when there are too few data points within a partition, in which case the level of the curve is determined by uniformly sampling from the range of the entire dataset. For the detailed theory of this method, see the Theory section part1dzeroreg.


\begin{DoxyParams}{Parameters}
{\em dataset} & The dataset to run the regression on. See the \hyperlink{dataset1d_8h_a12b327d93f135ffa89af1d4d2359f771}{dataset1d\+\_\+load\+\_\+known}, \+::dataset1d\+\_\+load\+\_\+estimated, and \hyperlink{dataset1d_8h_a8a3dee8031d5f30f9698874806bb33be}{dataset1d\+\_\+load\+\_\+fixed} functions. \\
\hline
{\em burnin} & The number of burn in iterations. \\
\hline
{\em total} & The total number of iterations. \\
\hline
{\em min\+\_\+part} & The minimum number of partitions to allow. \\
\hline
{\em max\+\_\+part} & The maximum number of partitions to allow. to the data. \\
\hline
{\em xsamples} & The number of samples to use for discretization of the horizontal axis. \\
\hline
{\em ysamples} & The number of samples to use for discretization of the vertical axis when computing mode, median, and credible intervals. \\
\hline
{\em credible\+\_\+interval} & The credible interval to use for results expressed as a ratio, i.\+e. 0.\+95 for the 95\% credible interval. \\
\hline
{\em pd} & The standard deviation to use when peturbing the x-\/position of a partition. The new position is moved by N(0, pd). \\
\hline
{\em random} & A function pointer to uniform random number generator to use. See the \hyperlink{rjmcmc__random_8h_ab82b2ece8acc3f5a05ff2f270794f9be}{rjmcmc\+\_\+uniform} function. \\
\hline
{\em normal} & A function pointer to the normal random number generator for generating normally distributed random numbers with 0 mean and a standard deviation of 1. See the \hyperlink{rjmcmc__random_8h_a0f9b049cec5095e2e1c1b3488de1d5c0}{rjmcmc\+\_\+normal} function. \\
\hline
{\em results} & A bit mask of results to store. See \hyperlink{resultset1d_8h_a1fffe49407333be24faf49976523f7a0}{resultset1d\+\_\+result\+\_\+t}. \\
\hline
{\em callback} & A user function to call for every sample for collecting extra statistics. Set to N\+U\+LL if this is not needed. \\
\hline
{\em user\+\_\+arg} & The user argument to pass to the callback function. \\
\hline
\end{DoxyParams}


References part1d\+::accepted, part1d\+::birth\+\_\+prob, part1d\+::current, part1d\+::current\+\_\+like, part1d\+::dataset, part1d\+::death\+\_\+prob, part1d\+::dy, part1d\+::lambda\+\_\+prob, \+\_\+dataset1d\+::lambdastd, part1d\+::move\+\_\+prob, part1d\+::normal, part1d\+::nprocesses, part1d\+::out, part1d\+\_\+zero\+\_\+clone(), part1d\+\_\+zero\+\_\+create(), part1d\+\_\+zero\+\_\+destroy(), part1d\+\_\+zero\+\_\+evaluate(), part1d\+\_\+zero\+\_\+initialize(), part1d\+\_\+zero\+\_\+lambda(), part1d\+\_\+zero\+\_\+misfit(), part1d\+\_\+zero\+\_\+partition\+\_\+position(), part1d\+\_\+zero\+\_\+partitions(), part1d\+\_\+zero\+\_\+propose\+\_\+birth(), part1d\+\_\+zero\+\_\+propose\+\_\+death(), part1d\+\_\+zero\+\_\+propose\+\_\+lambda(), part1d\+\_\+zero\+\_\+propose\+\_\+move(), part1d\+\_\+zero\+\_\+propose\+\_\+value(), part1d\+::partitions, part1d\+::process, part1d\+::proposed, part1d\+::proposed\+\_\+like, part1d\+::random, part1d\+::results, resultset1d\+\_\+accept(), resultset1d\+\_\+assemble\+\_\+results(), resultset1d\+\_\+create(), resultset1d\+\_\+propose(), resultset1d\+\_\+sample(), resultset1d\+\_\+sample\+\_\+lambda(), resultset1d\+\_\+sample\+\_\+misfit(), resultset1d\+\_\+sample\+\_\+npartitions(), resultset1d\+\_\+sample\+\_\+partition\+\_\+x(), rjmcmc\+\_\+create\+\_\+array\+\_\+1d(), rjmcmc\+\_\+destroy\+\_\+array\+\_\+1d(), rjmcmc\+\_\+engine\+\_\+run(), rjmcmc\+\_\+error(), part1d\+::user\+\_\+arg, part1d\+::user\+\_\+callback, part1d\+::v, part1d\+::value\+\_\+prob, \+\_\+dataset1d\+::xmax, \+\_\+dataset1d\+::xmin, part1d\+::xsamples, \+\_\+dataset1d\+::ymax, and \+\_\+dataset1d\+::ymin.

\index{regression.\+h@{regression.\+h}!part2d\+\_\+regression@{part2d\+\_\+regression}}
\index{part2d\+\_\+regression@{part2d\+\_\+regression}!regression.\+h@{regression.\+h}}
\subsubsection[{\texorpdfstring{part2d\+\_\+regression(const dataset2d\+\_\+t $\ast$dataset, int burnin, int total, int min\+\_\+part, int max\+\_\+part, int xsamples, int ysamples, int zsamples, double credible\+\_\+interval, double pv, double pd, rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t random, rjmcmc\+\_\+normal\+\_\+rand\+\_\+t normal, int results, regression2d\+\_\+cb\+\_\+t user\+\_\+callback, void $\ast$user\+\_\+arg)}{part2d_regression(const dataset2d_t *dataset, int burnin, int total, int min_part, int max_part, int xsamples, int ysamples, int zsamples, double credible_interval, double pv, double pd, rjmcmc_uniform_rand_t random, rjmcmc_normal_rand_t normal, int results, regression2d_cb_t user_callback, void *user_arg)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf resultset2d\+\_\+t}$\ast$ part2d\+\_\+regression (
\begin{DoxyParamCaption}
\item[{const {\bf dataset2d\+\_\+t} $\ast$}]{dataset, }
\item[{int}]{burnin, }
\item[{int}]{total, }
\item[{int}]{min\+\_\+part, }
\item[{int}]{max\+\_\+part, }
\item[{int}]{xsamples, }
\item[{int}]{ysamples, }
\item[{int}]{zsamples, }
\item[{double}]{credible\+\_\+interval, }
\item[{double}]{pv, }
\item[{double}]{pd, }
\item[{{\bf rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t}}]{random, }
\item[{{\bf rjmcmc\+\_\+normal\+\_\+rand\+\_\+t}}]{normal, }
\item[{int}]{results, }
\item[{{\bf regression2d\+\_\+cb\+\_\+t}}]{user\+\_\+callback, }
\item[{void $\ast$}]{user\+\_\+arg}
\end{DoxyParamCaption}
)}\hypertarget{regression_8h_aa4589a0fbb1ca56b2db6fafbda40161f}{}\label{regression_8h_aa4589a0fbb1ca56b2db6fafbda40161f}


References part2d\+::accepted, part2d\+::birth\+\_\+prob, part2d\+::current, part2d\+::current\+\_\+like, part2d\+::dataset, part2d\+::death\+\_\+prob, part2d\+::dpart, part2d\+::dz, part2d\+::lambda\+\_\+prob, \+\_\+dataset2d\+::lambdastd, part2d\+::move\+\_\+prob, part2d\+::normal, part2d\+::nprocesses, part2d\+::out, part2d\+\_\+regression\+\_\+rj\+\_\+clone(), part2d\+\_\+regression\+\_\+rj\+\_\+create(), part2d\+\_\+regression\+\_\+rj\+\_\+destroy(), part2d\+\_\+regression\+\_\+rj\+\_\+evaluate(), part2d\+\_\+regression\+\_\+rj\+\_\+initialize(), part2d\+\_\+regression\+\_\+rj\+\_\+lambda(), part2d\+\_\+regression\+\_\+rj\+\_\+misfit(), part2d\+\_\+regression\+\_\+rj\+\_\+partition\+\_\+centre(), part2d\+\_\+regression\+\_\+rj\+\_\+partitions(), part2d\+\_\+regression\+\_\+rj\+\_\+propose\+\_\+birth(), part2d\+\_\+regression\+\_\+rj\+\_\+propose\+\_\+death(), part2d\+\_\+regression\+\_\+rj\+\_\+propose\+\_\+lambda(), part2d\+\_\+regression\+\_\+rj\+\_\+propose\+\_\+move(), part2d\+\_\+regression\+\_\+rj\+\_\+propose\+\_\+value(), part2d\+\_\+regression\+\_\+rj\+\_\+value\+\_\+at(), part2d\+::process, part2d\+::proposed, part2d\+::proposed\+\_\+like, part2d\+::random, part2d\+::results, resultset2d\+\_\+accept(), resultset2d\+\_\+assemble\+\_\+results(), resultset2d\+\_\+create(), resultset2d\+\_\+propose(), resultset2d\+\_\+sample(), resultset2d\+\_\+sample\+\_\+centre(), resultset2d\+\_\+sample\+\_\+lambda(), resultset2d\+\_\+sample\+\_\+misfit(), resultset2d\+\_\+sample\+\_\+npartitions(), rjmcmc\+\_\+create\+\_\+array\+\_\+1d(), rjmcmc\+\_\+create\+\_\+array\+\_\+2d(), rjmcmc\+\_\+destroy\+\_\+array\+\_\+1d(), rjmcmc\+\_\+destroy\+\_\+array\+\_\+2d(), rjmcmc\+\_\+engine\+\_\+run(), rjmcmc\+\_\+error(), rjmcmc\+\_\+random\+\_\+choose\+\_\+int(), part2d\+::user\+\_\+arg, part2d\+::user\+\_\+callback, part2d\+::user\+\_\+x\+\_\+centre, part2d\+::user\+\_\+y\+\_\+centre, part2d\+::v, part2d\+::value\+\_\+prob, x, \+\_\+dataset2d\+::xmax, \+\_\+dataset2d\+::xmin, part2d\+::xsamples, y, \+\_\+dataset2d\+::ymax, \+\_\+dataset2d\+::ymin, part2d\+::ysamples, \+\_\+dataset2d\+::zmax, and \+\_\+dataset2d\+::zmin.

\index{regression.\+h@{regression.\+h}!single1d\+\_\+direct\+\_\+regression@{single1d\+\_\+direct\+\_\+regression}}
\index{single1d\+\_\+direct\+\_\+regression@{single1d\+\_\+direct\+\_\+regression}!regression.\+h@{regression.\+h}}
\subsubsection[{\texorpdfstring{single1d\+\_\+direct\+\_\+regression(const dataset1d\+\_\+t $\ast$dataset, const double $\ast$fixed\+\_\+prior, int max\+\_\+order, int xsamples, rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t random, rjmcmc\+\_\+normal\+\_\+rand\+\_\+t normal)}{single1d_direct_regression(const dataset1d_t *dataset, const double *fixed_prior, int max_order, int xsamples, rjmcmc_uniform_rand_t random, rjmcmc_normal_rand_t normal)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf resultset1d\+\_\+t}$\ast$ single1d\+\_\+direct\+\_\+regression (
\begin{DoxyParamCaption}
\item[{const {\bf dataset1d\+\_\+t} $\ast$}]{dataset, }
\item[{const double $\ast$}]{fixed\+\_\+prior, }
\item[{int}]{max\+\_\+order, }
\item[{int}]{xsamples, }
\item[{{\bf rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t}}]{random, }
\item[{{\bf rjmcmc\+\_\+normal\+\_\+rand\+\_\+t}}]{normal}
\end{DoxyParamCaption}
)}\hypertarget{regression_8h_a0ab9525ab0dc478cfa18bc9bd5a94d97}{}\label{regression_8h_a0ab9525ab0dc478cfa18bc9bd5a94d97}


Single Partition Regression with direct integration. 

The \hyperlink{regression_8h_a037d789bc3de5c4c55b0c781193ae3b7}{single1d\+\_\+regression} samples the fit of polynomials drawn from a distribution but it is possible to integrate these out directly and avoid the stochastic sampling process. The benefit of this is that the regression is performed quicker. The downside is that results such as credible intervals are unavailable. 

References curvefit\+\_\+create(), curvefit\+\_\+evaluate\+\_\+pk(), single1d\+::det\+Cm, single1d\+::kcdf, single1d\+::max\+\_\+order, single1d\+::mean, single1d\+::mean\+\_\+misfit, \+\_\+dataset1d\+::npoints, single1d\+::pk, single1d\+::results, resultset1d\+\_\+create(), R\+E\+S\+U\+L\+T\+S\+E\+T1\+D\+\_\+\+M\+E\+AN, resultset1d\+\_\+sample(), rjmcmc\+\_\+create\+\_\+array\+\_\+1d(), rjmcmc\+\_\+create\+\_\+array\+\_\+2d(), rjmcmc\+\_\+destroy\+\_\+array\+\_\+1d(), rjmcmc\+\_\+destroy\+\_\+array\+\_\+2d(), rjmcmc\+\_\+error(), rjmcmc\+\_\+polynomial\+\_\+value(), single1d\+::S, single1d\+::sigma, x, \+\_\+dataset1d\+::xmax, \+\_\+dataset1d\+::xmin, \+\_\+dataset1d\+::ymax, and \+\_\+dataset1d\+::ymin.

\index{regression.\+h@{regression.\+h}!single1d\+\_\+regression@{single1d\+\_\+regression}}
\index{single1d\+\_\+regression@{single1d\+\_\+regression}!regression.\+h@{regression.\+h}}
\subsubsection[{\texorpdfstring{single1d\+\_\+regression(const dataset1d\+\_\+t $\ast$dataset, int burnin, int total, int max\+\_\+order, int xsamples, int ysamples, double credible\+\_\+interval, rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t random, rjmcmc\+\_\+normal\+\_\+rand\+\_\+t normal, int results, regression1d\+\_\+cb\+\_\+t user\+\_\+callback, void $\ast$user\+\_\+arg)}{single1d_regression(const dataset1d_t *dataset, int burnin, int total, int max_order, int xsamples, int ysamples, double credible_interval, rjmcmc_uniform_rand_t random, rjmcmc_normal_rand_t normal, int results, regression1d_cb_t user_callback, void *user_arg)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf resultset1d\+\_\+t}$\ast$ single1d\+\_\+regression (
\begin{DoxyParamCaption}
\item[{const {\bf dataset1d\+\_\+t} $\ast$}]{dataset, }
\item[{int}]{burnin, }
\item[{int}]{total, }
\item[{int}]{max\+\_\+order, }
\item[{int}]{xsamples, }
\item[{int}]{ysamples, }
\item[{double}]{credible\+\_\+interval, }
\item[{{\bf rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t}}]{random, }
\item[{{\bf rjmcmc\+\_\+normal\+\_\+rand\+\_\+t}}]{normal, }
\item[{int}]{results, }
\item[{{\bf regression1d\+\_\+cb\+\_\+t}}]{user\+\_\+callback, }
\item[{void $\ast$}]{user\+\_\+arg}
\end{DoxyParamCaption}
)}\hypertarget{regression_8h_a037d789bc3de5c4c55b0c781193ae3b7}{}\label{regression_8h_a037d789bc3de5c4c55b0c781193ae3b7}


Single Partition Regression. 

The \hyperlink{regression_8h_a037d789bc3de5c4c55b0c781193ae3b7}{single1d\+\_\+regression} function performs a regression simulation on a single partition of the given dataset. It will attempt to fit trial polynomials of order 0 to order\+\_\+max and sampling acceptable polynomials at each order. The method of selecting the order of the polynomial (or the probability distribution of the order of the data) is outlined in {\bfseries [sambridge2006A]}.

The results are returned in a \hyperlink{resultset1d_8h_ae2ef1c63a8e796e51d39d8b7c2cdfa72}{resultset1d\+\_\+t} structure that can be interrogated with various functions in \+::resultset1d.\+h.

For example of the use of this function, see 1d/single/regression/cubic/cubic.\+c


\begin{DoxyParams}{Parameters}
{\em dataset} & The dataset to run the regression on. See the \hyperlink{dataset1d_8h_a12b327d93f135ffa89af1d4d2359f771}{dataset1d\+\_\+load\+\_\+known}, \+::dataset1d\+\_\+load\+\_\+estimated, and \hyperlink{dataset1d_8h_a8a3dee8031d5f30f9698874806bb33be}{dataset1d\+\_\+load\+\_\+fixed} functions. \\
\hline
{\em burnin} & The number of burn in iterations. \\
\hline
{\em total} & The total number of iterations. \\
\hline
{\em max\+\_\+order} & The maximum order of the polynomial to allow when fitting a trial curve to the data. \\
\hline
{\em xsamples} & The number of samples to use for discretization of the horizontal axis. \\
\hline
{\em ysamples} & The number of samples to use for discretization of the vertical axis when computing mode, median, and credible intervals. \\
\hline
{\em credible\+\_\+interval} & The credible interval to use for results expressed as a ratio, i.\+e. 0.\+95 for the 95\% credible interval. \\
\hline
{\em random} & A function pointer to uniform random number generator to use. See the \hyperlink{rjmcmc__random_8h_ab82b2ece8acc3f5a05ff2f270794f9be}{rjmcmc\+\_\+uniform} function. \\
\hline
{\em normal} & A function pointer to the normal random number generator for generating normally distributed random numbers with 0 mean and a standard deviation of 1. See the \hyperlink{rjmcmc__random_8h_a0f9b049cec5095e2e1c1b3488de1d5c0}{rjmcmc\+\_\+normal} function. \\
\hline
{\em results} & A bit mask of results to store. See \hyperlink{resultset1d_8h_a1fffe49407333be24faf49976523f7a0}{resultset1d\+\_\+result\+\_\+t}. \\
\hline
{\em user\+\_\+callback} & An optional callback function to do your own sampling of the generated curves. Set to N\+U\+LL if you don\textquotesingle{}t need this. \\
\hline
{\em user\+\_\+arg} & A user pointer to pass to the callback function. \\
\hline
\end{DoxyParams}
\index{regression.\+h@{regression.\+h}!single1d\+\_\+regression\+\_\+with\+\_\+prior@{single1d\+\_\+regression\+\_\+with\+\_\+prior}}
\index{single1d\+\_\+regression\+\_\+with\+\_\+prior@{single1d\+\_\+regression\+\_\+with\+\_\+prior}!regression.\+h@{regression.\+h}}
\subsubsection[{\texorpdfstring{single1d\+\_\+regression\+\_\+with\+\_\+prior(const dataset1d\+\_\+t $\ast$dataset, const double $\ast$prior, int burnin, int total, int max\+\_\+order, int xsamples, int ysamples, double credible\+\_\+interval, rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t random, rjmcmc\+\_\+normal\+\_\+rand\+\_\+t normal, int results, regression1d\+\_\+cb\+\_\+t user\+\_\+callback, void $\ast$user\+\_\+arg)}{single1d_regression_with_prior(const dataset1d_t *dataset, const double *prior, int burnin, int total, int max_order, int xsamples, int ysamples, double credible_interval, rjmcmc_uniform_rand_t random, rjmcmc_normal_rand_t normal, int results, regression1d_cb_t user_callback, void *user_arg)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf resultset1d\+\_\+t}$\ast$ single1d\+\_\+regression\+\_\+with\+\_\+prior (
\begin{DoxyParamCaption}
\item[{const {\bf dataset1d\+\_\+t} $\ast$}]{dataset, }
\item[{const double $\ast$}]{prior, }
\item[{int}]{burnin, }
\item[{int}]{total, }
\item[{int}]{max\+\_\+order, }
\item[{int}]{xsamples, }
\item[{int}]{ysamples, }
\item[{double}]{credible\+\_\+interval, }
\item[{{\bf rjmcmc\+\_\+uniform\+\_\+rand\+\_\+t}}]{random, }
\item[{{\bf rjmcmc\+\_\+normal\+\_\+rand\+\_\+t}}]{normal, }
\item[{int}]{results, }
\item[{{\bf regression1d\+\_\+cb\+\_\+t}}]{user\+\_\+callback, }
\item[{void $\ast$}]{user\+\_\+arg}
\end{DoxyParamCaption}
)}\hypertarget{regression_8h_ac8c2d9357e8a0ac1ff03fc48843e804b}{}\label{regression_8h_ac8c2d9357e8a0ac1ff03fc48843e804b}


Single Partition Regression with a custom prior. 

Deprecated. Used for testing. 